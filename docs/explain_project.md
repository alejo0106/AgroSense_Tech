# üß© Explicaci√≥n Integral del Proyecto AgroSense Tech

Bienvenido: aqu√≠ entender√°s, paso a paso y desde cero, qu√© es AgroSense Tech, c√≥mo est√° organizado el c√≥digo, c√≥mo fluyen los datos desde los sensores hasta el dashboard, c√≥mo se prueba su calidad y qu√© est√°ndares seguimos (ISO/IEC 25010, ISO/IEC 29119, ISTQB).

---

## üéØ Qu√© es AgroSense Tech y por qu√© existe

- AgroSense Tech es una plataforma IoT de monitoreo agr√≠cola. Recibe lecturas de sensores (temperatura, humedad, pH, luz), las almacena, calcula m√©tricas agregadas y las muestra en un dashboard web.
- Problema que resuelve: dar visibilidad r√°pida y fiable del estado del cultivo para tomar decisiones (riego, luz, correcciones de pH). Conecta IoT (captura) + an√°lisis de datos (m√©tricas) + automatizaci√≥n (visualizaci√≥n, CI/CD, pruebas).
- Est√°ndares de calidad:
  - ISO/IEC 25010: gu√≠a de atributos de calidad (fiabilidad, mantenibilidad, usabilidad‚Ä¶).
  - ISO/IEC 29119: proceso de pruebas (planificaci√≥n ‚Üí ejecuci√≥n ‚Üí reporte).
  - ISTQB: t√©cnicas y niveles de prueba (caja negra, caja blanca; unitarias, integraci√≥n, sistema, aceptaci√≥n).

---

## üß± Visi√≥n general de la estructura

Carpetas y archivos clave en la ra√≠z del repositorio:

- `main.py`: crea la app FastAPI, registra routers, inicializa la BD y redirige `/` ‚Üí `/dashboard/view`.
- `database.py`: motor SQLAlchemy, `SessionLocal`, `Base`, `init_db()`, `get_db()`, y `get_connection()` (psycopg2). Admite `PostgreSQL` o `SQLite` (fallback).
- `models.py`: modelo ORM `Sensor` y esquemas Pydantic para validar/serializar datos.
- `routers/`:
  - `sensors.py`: POST `/sensor-data` (ingesta de lecturas).
  - `analytics.py`: GET `/analytics` (m√©tricas avg/max/min) y funci√≥n `process_data()`.
  - `dashboard.py`: GET `/dashboard` (resumen JSON para frontends o integraciones).
  - `dashboard_html.py`: GET `/dashboard/view` (render HTML con Jinja2).
- `templates/dashboard.html`: plantilla del dashboard (Jinja2 + Plotly.js).
- `scripts/`: herramientas para sembrar/verificar la base de datos (`seed_from_sql.py`, `seed_db.py`, `verify_connection.py`).
- `tests/`: suite de pruebas (unitarias, integraci√≥n, sistema) con pytest.
- `.github/workflows/ci.yml`: pipeline de CI (instalaci√≥n, pruebas, cobertura, artefactos).
- `docs/`: documentaci√≥n LaTeX/IEEE y diagramas Mermaid.
- `docker-compose.yml`: stack listo (Postgres + app) para un entorno reproducible.

C√≥mo se conectan las piezas (flujo de trabajo de alto nivel):
1) Cliente (sensor o script) env√≠a una lectura a POST `/sensor-data`.
2) La API valida y guarda en la base (SQLAlchemy ORM).
3) El dashboard y los endpoints de anal√≠tica leen las lecturas, calculan m√©tricas y devuelven JSON o HTML.
4) La suite de pruebas verifica estos flujos y el pipeline CI las ejecuta autom√°ticamente.

---

## ‚öôÔ∏è Backend y API (FastAPI)

FastAPI es el framework que expone los endpoints REST.

- App principal: `main.py`
  - Llama a `init_db()` al arrancar para crear tablas.
  - Registra routers: `sensors`, `analytics`, `dashboard`, `dashboard_html`.
  - Redirecci√≥n √∫til: `/` ‚Üí `/dashboard/view`.

Routers principales:
- `routers/sensors.py` (ingesta)
  - Endpoint: `POST /sensor-data`.
  - Entrada validada con Pydantic (`SensorCreate`): `sensor_id`, `temperature`, `humidity`, `ph`, `light`, `timestamp` (opcional).
  - Persiste una instancia `Sensor` (ORM) y confirma con `commit()`.
- `routers/analytics.py` (anal√≠tica)
  - Endpoint: `GET /analytics`.
  - Consulta todas las lecturas, arma una lista de dicts y llama a `process_data()`.
  - Devuelve un JSON con sub-objetos por variable: `temperature`, `humidity`, `ph`, `light`; cada uno con `avg`, `max`, `min`.
- `routers/dashboard.py` (resumen JSON)
  - Endpoint: `GET /dashboard`.
  - Similar a analytics, pero adem√°s incluye `count` de lecturas y algunas m√©tricas de conveniencia.
- `routers/dashboard_html.py` (vista HTML)
  - Endpoint: `GET /dashboard/view`.
  - Renderiza `templates/dashboard.html` con `Jinja2Templates`.

Swagger y documentaci√≥n interactiva:
- FastAPI expone autom√°ticamente la documentaci√≥n en:
  - Swagger UI: `http://127.0.0.1:8000/docs`
  - Redoc: `http://127.0.0.1:8000/redoc`
- Para ‚Äúbuscar el Swagger en Google‚Äù: basta con abrir el navegador y escribir `localhost:8000/docs` o, si est√° desplegado con un dominio, `https://tu-dominio/docs`.

Validaci√≥n con Pydantic (v2):
- `models.py` define `SensorCreate` (entrada) y `SensorOut` (salida). Con `ConfigDict(from_attributes=True)` podemos serializar desde objetos ORM sin esfuerzo.

---

## üóÑÔ∏è Persistencia y Base de Datos (SQLAlchemy + PostgreSQL/SQLite)

Modelos ORM:
- `models.Sensor` mapea la tabla `sensor_data` con columnas: `id`, `sensor_id`, `temperature`, `humidity`, `ph`, `light`, `timestamp` (con `server_default=func.now()`).

Sesi√≥n y motor:
- `database.SessionLocal`: factor√≠a de sesiones.
- `database.get_db()`: dependencia FastAPI que abre una sesi√≥n por request y la cierra al final (patr√≥n recomendado).
- `database.init_db()`: importa modelos y crea tablas (`Base.metadata.create_all`).

Conexi√≥n y configuraci√≥n:
- Prioridad para elegir motor (`database.DATABASE_URL`):
  1) `POSTGRES_DSN` (si se define expl√≠citamente),
  2) `DATABASE_URL`,
  3) fallback `sqlite:///agrosense.db`.
- Para diagn√≥sticos directos con psycopg2: `database.get_connection()` resuelve DSN (Postgres) y devuelve una conexi√≥n con `RealDictCursor`.

Scripts de apoyo (carpeta `scripts/`):
- `verify_connection.py`: imprime variables relevantes y verifica conexi√≥n a Postgres.
- `seed_from_sql.py`: ejecuta `scripts/seed_data.sql` (crea/llena la tabla y una vista ejemplo).
- `seed_db.py`: siembra lecturas de ejemplo usando el ORM.

Notas pr√°cticas:
- Para desarrollo local con rapidez, puedes usar SQLite (sin levantar Postgres). Para demos y producci√≥n, usa PostgreSQL.
- Se soporta `.env` (si `python-dotenv` est√° instalado) para cargar `DATABASE_URL` y `POSTGRES_*` sin exponer credenciales en el repo.

---

## üìä Dashboard y visualizaci√≥n (Jinja2 + Plotly.js)

Plantilla: `templates/dashboard.html`
- Estructura visual con CSS + KPIs + 4 gr√°ficos de barras (Plotly.js) para temperatura, humedad, pH y luz.
- Carga datos de `/analytics` v√≠a `fetch` y actualiza KPIs y gr√°ficas.
- Bot√≥n ‚ÄúActualizar‚Äù y marca de tiempo de la √∫ltima actualizaci√≥n.

Relaci√≥n con el backend:
- La vista HTML puede renderizarse servidor-side (`/dashboard/view`) o consumirse via JSON (`/analytics`).
- El c√°lculo de m√©tricas lo centraliza `process_data()` para evitar duplicidad de l√≥gica.

Tip √∫til:
- Puedes ‚Äúguardar‚Äù la p√°gina ya renderizada sin servidor usando un cliente de prueba (se dej√≥ un ejemplo en el README para generar `dashboard_view.html`).

---

## üß™ Pruebas y Calidad (pytest + cobertura)

Estructura de `tests/`:
- `test_unit/`: pruebas unitarias (p. ej., `test_process_data.py`, `test_database_helpers.py`, `test_sensors_unit.py`).
- `test_integration/`: integraci√≥n de endpoints y DB (`test_analytics_integration.py`, `test_dashboard_integration.py`, `test_dashboard_json_integration.py`).
- `test_system/`: end-to-end (`test_end_to_end.py`).
- `conftest.py`: fixtures compartidas (`client` y `db_session`).
- Algunos archivos ‚Äúplaceholder‚Äù documentan consolidaciones de tests legados.

Tipos de pruebas:
- Unitarias: funciones puras (como `process_data`) y helpers de DB.
- Integraci√≥n: routers + persistencia (verifican JSON, estados vac√≠os y consistencia).
- Sistema (E2E): ingesta ‚Üí anal√≠tica; confirma que min/max/avg cubren los valores enviados.

Fixtures:
- `client`: instancia `TestClient(app)` para llamadas HTTP internas.
- `db_session`: crea y limpia la tabla de sensor antes de cada prueba (aislamiento y repetibilidad, alineado a ISO/IEC 29119).

Cobertura:
- La CI ejecuta `pytest --cov=.` y publica reportes HTML/XML como artefactos.
- Cobertura global actual: ~91% (seg√∫n los reportes LaTeX y CI). Esto refleja buena mantenibilidad y testabilidad (ISO/IEC 25010).

Pruebas cr√≠ticas (qu√© validan):
- `/sensor-data` acepta payload v√°lido y rechaza entradas inv√°lidas (tipos y campos faltantes).
- `/analytics` devuelve estructura anidada con `avg`, `max`, `min` y se comporta bien si no hay datos.
- `/dashboard/view` carga el HTML y muestra el branding; `/dashboard` (JSON) reporta `count` y m√©tricas.
- Helpers de `database.py` manejan la selecci√≥n de DSN, la creaci√≥n de tablas y errores de conexi√≥n coherentemente.

---

## ü§ñ Automatizaci√≥n y CI/CD (GitHub Actions)

Archivo: `.github/workflows/ci.yml`
- Se ejecuta en `push` y `pull_request` contra `main`.
- Estrategia de matrices Python 3.11 y 3.12.
- Pasos principales:
  1) Instala dependencias (incluye `psycopg2-binary` y librer√≠as del sistema para compilar si hiciera falta).
  2) Ejecuta `pytest` con cobertura (term, XML y HTML) y sube artefactos de cobertura (`htmlcov/`, `coverage.xml`, `.coverage.*`).
  3) Job adicional que combina cobertura ‚Äúraw‚Äù entre versiones y publica un HTML/XML combinado (cuando corresponde).

¬øPor qu√© es importante?
- Ejecuta pruebas en entornos limpios (reproducibles).
- Detecta regresiones temprano.
- Sirve de evidencia objetiva de proceso (ISO/IEC 29119) y respalda atributos de calidad (ISO/IEC 25010: fiabilidad, mantenibilidad, portabilidad).

---

## üß≠ Arquitectura y diagramas (Mermaid)

Archivos en `docs/`:
- `diagrama_arquitectura.mmd`: visi√≥n ‚Äúampliada‚Äù orientada a nube (AWS IoT Core, Kinesis, Lambda, Timestream, DynamoDB, S3, SageMaker, API Gateway, Cognito, CloudFront, ECS). Muestra un pipeline t√≠pico: sensores ‚Üí ingesta ‚Üí procesamiento ‚Üí almacenamiento ‚Üí anal√≠tica/ML ‚Üí API ‚Üí frontend/CDN ‚Üí navegador.
- `web_application_architecture.mmd`: maqueta de aplicaci√≥n web que ilustra roles de ‚Äúservidor de aplicaci√≥n‚Äù, ‚Äúbase de datos‚Äù y ‚Äúfrontend‚Äù. Aunque menciona ‚ÄúFlask‚Äù y ‚ÄúChart.js‚Äù (gen√©rico), en este proyecto los equivalentes reales son FastAPI y Plotly.js.

Flujo de datos explicado (de extremo a extremo):
1) Sensores env√≠an lecturas (IoT). En la demo, lo simulas con requests al endpoint de ingesta.
2) Backend recibe, valida y almacena (FastAPI + SQLAlchemy + Postgres/SQLite).
3) El servicio de anal√≠tica agrega y expone m√©tricas (GET `/analytics`).
4) El dashboard (Jinja2 + Plotly.js) consulta esas m√©tricas y las visualiza.
5) CI/CD valida continuamente que estos flujos sigan funcionando.

---

## üß† Est√°ndares aplicados (ISO/IEC 25010, ISO/IEC 29119, ISTQB)

- ISO/IEC 25010 (calidad del producto):
  - Adecuaci√≥n funcional: endpoints cumplen con su prop√≥sito (ingesta, anal√≠tica, visualizaci√≥n) y est√°n cubiertos por pruebas.
  - Fiabilidad: suite multi-nivel sin fallos cr√≠ticos; manejo de estados vac√≠os.
  - Mantenibilidad: arquitectura modular, alta cobertura, comentarios y separaci√≥n de responsabilidades.
  - Usabilidad: dashboard claro con KPIs y gr√°ficos.
  - Portabilidad/Compatibilidad: configuraci√≥n por entorno; corre en Linux/Windows; fallback a SQLite.
- ISO/IEC 29119 (proceso de pruebas):
  - Evidencias: plan LaTeX (`plan_pruebas_agrosense.tex`), reporte (`reporte_pruebas.tex`), criterios de entrada/salida, trazabilidad.
  - Actividades: planificaci√≥n ‚Üí dise√±o ‚Üí implementaci√≥n ‚Üí ejecuci√≥n (CI) ‚Üí evaluaci√≥n/cierre.
- ISTQB (t√©cnicas y niveles):
  - Caja negra: validaci√≥n de endpoints y contratos de respuesta.
  - Caja blanca: paths internos (helpers, bordes de agregaci√≥n). 
  - Niveles: unitarias, integraci√≥n, sistema; aceptaci√≥n planificada.

¬øD√≥nde se evidencia en el repo?
- C√≥digo comentado (routers, `database.py`, `models.py`).
- Suite `tests/` organizada por niveles.
- CI que ejecuta y reporta cobertura.
- Documentos en `docs/` con plan, reporte y contexto.

---

## üìö Documentaci√≥n y evidencias (LaTeX, m√©tricas)

En `docs/`:
- `plan_pruebas_agrosense.tex`: plan de pruebas (IEEEtran) ‚Äî objetivos, alcance, estrategia, trazabilidad a ISO 25010 e ISO 29119, matriz de planificaci√≥n.
- `reporte_pruebas.tex`: reporte de pruebas ‚Äî resultados, cobertura (~91%), conclusiones y mejoras.
- `contexto_requerimientos_agrosense.tex`: contexto, buyer persona, requerimientos t√©cnicos y est√°ndares.
- Diagramas: `diagrama_arquitectura.mmd`, `web_application_architecture.mmd` (+ PNGs exportados).

Relaciones:
- Contexto ‚Üí Plan ‚Üí Ejecuci√≥n en CI ‚Üí Reporte (+ artefactos de cobertura). Las tablas y m√©tricas dan evidencia objetiva para sustentar conclusiones.

---

## üöÄ Mejoras y extensiones sugeridas

Estado actual (completo):
- Ingesta, anal√≠tica y dashboard operativos.
- Persistencia con SQLAlchemy; Postgres preferido y SQLite de respaldo.
- Suite de pruebas multi-nivel y CI con cobertura.
- Documentaci√≥n t√©cnica y diagramas.

Pendiente / siguientes pasos de valor:
- Migraciones con Alembic (versionado del esquema en Postgres).
- Seguridad: autenticaci√≥n/autorizaci√≥n (tokens), HTTPS y pruebas negativas 401/403.
- Rendimiento: simulador IoT para estr√©s/carga y umbrales en CI.
- Integraci√≥n con Codecov para publicar tendencia de cobertura (objetivo ‚â•95%).
- Limpieza/curaci√≥n de datos: reglas para filtrar lecturas inv√°lidas (p. ej., valores cero por defecto de prueba) y endpoints de mantenimiento en dev.
- Despliegue: Docker Compose ya existe; extender a infraestructura cloud (por ejemplo, AWS ECS/Fargate + RDS + CloudFront) seg√∫n el diagrama.

C√≥mo escalar a producci√≥n (ruta ejemplo):
1) A√±adir Alembic y pipeline de migraciones.
2) Endpoints protegidos y secretos gestionados (AWS Secrets Manager/HashiCorp Vault).
3) Observabilidad: logs estructurados, m√©tricas, trazas (OpenTelemetry).
4) CI/CD avanzado: Codecov + escaneo de seguridad + pruebas de carga en gates.
5) Infra: contenedores en ECS/Fargate o Kubernetes; RDS Postgres; CDN para est√°ticos.

---

## üìå Referencias r√°pidas (uso)

- API Docs (Swagger): `http://127.0.0.1:8000/docs`
- Dashboard (HTML): `http://127.0.0.1:8000/dashboard/view`
- M√©tricas (JSON): `http://127.0.0.1:8000/analytics`
- Docker (r√°pido): `docker compose up -d --build`
- Tests locales: `python -m pytest -q`

---

Si necesitas una gu√≠a de presentaci√≥n (paso a paso con comandos), ya est√° en `README.md` con flujo recomendado para mostrar al profesor.
